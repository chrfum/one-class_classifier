{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from collections import defaultdict\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "import itertools\n",
    "import logging\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130, 367)\n",
      "(130, 326)\n",
      "(130, 274)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/run-over-dataset.csv\")\n",
    "print(df.shape)\n",
    "\n",
    "columns_to_drop = ['VERBALE', 'DATA', 'Tot Testa', 'Tot Torace', 'Tot Addome', 'Tot Scheletro',\n",
    "                    'Totale', 'Tot Volta cranica', 'Tot Base cranica', \n",
    "                    'Tot Neuroc.', 'Tot Splancnoc.', 'Tot Testa',\n",
    "                    'Tot Tratto toracico', 'Tot Tratto lombare', 'Tot Rachide',\n",
    "                    ' Totale coste', 'Sterno in toto', 'Tot Bacino', 'I costa dx', 'II costa dx',\n",
    "                    'III costa dx', 'IV costa dx', 'V costa dx', 'VI costa dx', 'VII costa dx', \n",
    "                    'VIII costa dx', 'IX costa dx', 'X costa dx', 'XI costa dx', 'XII costa dx',\n",
    "                    'I costa sx', 'II costa sx', 'III costa sx', 'IV costa sx', 'V costa sx', \n",
    "                    'VI costa sx', 'VII costa sx', 'VIII costa sx', 'IX costa sx', \n",
    "                    'X costa sx', 'XI costa sx', 'XII costa sx']\n",
    "\n",
    "X = df.drop(columns=columns_to_drop)\n",
    "print(X.shape)\n",
    "\n",
    "X['ALTEZZA'] = [int(float(h.replace(',', '.'))*100) for h in X['ALTEZZA']]\n",
    "X['PESO'] = [int(float(str(h).replace(',', '.'))) for h in X['PESO']]\n",
    "X['BMI'] = [float(str(h).replace(',', '.')) for h in X['BMI']]\n",
    "\n",
    "num_unique_values = X.nunique()\n",
    "constant_columns = num_unique_values[num_unique_values == 1].index.tolist()\n",
    "\n",
    "X = X.drop(columns=constant_columns)\n",
    "X = X.T.drop_duplicates().T\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_columns(X):\n",
    "    X = X.drop(columns='Mezzo')\n",
    "\n",
    "    binary_columns = [col for col in X.columns if set(X[col].unique()).issubset({0, 1})]\n",
    "    X = X[binary_columns]\n",
    "\n",
    "    columns = []\n",
    "    column_scores = []\n",
    "\n",
    "    for col in X.columns:\n",
    "        n1 = sum([1 if x == 1 else 0 for x in X[col]])\n",
    "        n0 = sum([1 if x == 0 else 0 for x in X[col]])\n",
    "\n",
    "        columns.append(col)\n",
    "        column_scores.append(n1 / (n1 + n0))\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(np.arange(0, len(column_scores)), column_scores, color='skyblue')\n",
    "    plt.xlabel('Colonne')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Score delle Colonne Binarie')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "    return\n",
    "\n",
    "plot_columns(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_columns(X, score_threshold):\n",
    "    binary_columns = [col for col in X.columns if set(X[col].unique()).issubset({0, 1})]\n",
    "    filtered_columns = [col for col in X.columns if not(set(X[col].unique()).issubset({0, 1}))]\n",
    "    X_binary = X[binary_columns]\n",
    "\n",
    "    for col in X_binary.columns:\n",
    "        n1 = sum(X_binary[col])\n",
    "        n0 = len(X_binary[col]) - n1\n",
    "        column_score = n1 / (n1 + n0)\n",
    "\n",
    "        if column_score >= score_threshold:\n",
    "            filtered_columns.append(col)\n",
    "\n",
    "    filtered_df = X[filtered_columns]\n",
    "\n",
    "    return filtered_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 3355825"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_record(df, record):\n",
    "    new_record = pd.DataFrame(record, index=[0])\n",
    "    df = pd.concat([df, new_record], ignore_index=True)\n",
    "    return df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_cv_svm(X, random_seed, threshold, decomposition=PCA, n_outer_folds=7, n_inner_folds=5, n_components=65, mod_selection_score=accuracy_score, positive_class=0):\n",
    "    kernels = ['linear', 'rbf']\n",
    "    gammas = np.logspace(-3, 3, 7)\n",
    "    nus = np.linspace(0.01, 0.50, 25) \n",
    "    scalers = [StandardScaler(), MinMaxScaler(), RobustScaler()]\n",
    "    \n",
    "    best_params = {'kernel': '', 'gamma': 0, 'nu': 0, 'components': 0, 'scaler': ''}\n",
    "    accuracy_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "    best_overall_accuracy = 0\n",
    "    best_overall_params = {'kernel': '', 'gamma': 0, 'nu': 0, 'components': 0, 'scaler': ''}\n",
    "\n",
    "    y = X['Mezzo'].values\n",
    "    y = np.array([0. if x == positive_class else 1. for x in y], dtype=float)\n",
    "    \n",
    "    X = X.drop(columns='Mezzo')\n",
    "    X = filter_columns(X, threshold)\n",
    "\n",
    "    outer_cv = StratifiedKFold(n_splits=n_outer_folds, shuffle=True, random_state=random_seed)\n",
    "        \n",
    "    for outer_cv_number, (train_idx, test_idx) in enumerate(outer_cv.split(X, y)):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        inner_cv = StratifiedKFold(n_splits=n_inner_folds, shuffle=True, random_state=random_seed)\n",
    "\n",
    "        best_score = 0\n",
    "        best_scaler = None\n",
    "        best_encoder = None\n",
    "        for inner_cv_number, (trainval_idx, valid_idx) in enumerate(inner_cv.split(X_train, y_train)):\n",
    "            for kernel in kernels:\n",
    "                param_combinations = itertools.product([kernel], gammas, nus, scalers)\n",
    "                \n",
    "                if kernel == 'linear':\n",
    "                    param_combinations = itertools.product(['linear'], [0.001], nus, scalers)\n",
    "                elif kernel == 'rbf':\n",
    "                    param_combinations = itertools.product(['rbf'], gammas, nus, scalers)\n",
    "\n",
    "                for params in param_combinations:\n",
    "                    scaler = params[3]\n",
    "                    X_trainval, X_valid = X_train[trainval_idx], X_train[valid_idx]\n",
    "                    y_trainval, y_valid = y_train[trainval_idx], y_train[valid_idx]\n",
    "\n",
    "                    X_trainval_scaled = scaler.fit_transform(X_trainval)\n",
    "                    X_valid_scaled = scaler.transform(X_valid)\n",
    "\n",
    "                    encoder = decomposition(n_components=n_components)\n",
    "                    encoder.fit(X_train)\n",
    "                    \n",
    "                    X_trainval_reduced = encoder.transform(X_trainval_scaled)\n",
    "                    X_valid_reduced = encoder.transform(X_valid_scaled)\n",
    "                        \n",
    "                    idxs_neg = np.where(y_trainval == 1)[0]\n",
    "                \n",
    "                    X_trainval_reduced = np.delete(X_trainval_reduced, idxs_neg, axis=0)\n",
    "                    y_trainval = np.delete(y_trainval, idxs_neg)\n",
    "\n",
    "                    clf = OneClassSVM(kernel=params[0], gamma=params[1], nu=params[2])\n",
    "                        \n",
    "                    clf.fit(X_trainval_reduced)\n",
    "                        \n",
    "                    pred_values = clf.predict(X_valid_reduced)\n",
    "                    true_values = [1 if y == 0 else -1 for y in y_valid]\n",
    "                        \n",
    "                    score = mod_selection_score(true_values, pred_values)\n",
    "                    curr_params = {\n",
    "                            'kernel': params[0],\n",
    "                            'gamma': params[1],\n",
    "                            'nu': params[2],\n",
    "                            'components': n_components,\n",
    "                            'scaler': params[3]\n",
    "                    }\n",
    "\n",
    "                    logging.info(f\"inner cv number: {inner_cv_number}, {mod_selection_score.__name__}: {score}, with params: {curr_params}\")\n",
    "                            \n",
    "                    if score > best_score:\n",
    "                        best_score = score\n",
    "                        best_encoder = encoder\n",
    "                        best_scaler = scaler\n",
    "                        best_params = curr_params\n",
    "\n",
    "        idxs_neg = np.where(y_train == 1)[0]\n",
    "        X_train = np.delete(X_train, idxs_neg, axis=0)\n",
    "        y_train = np.delete(y_train, idxs_neg)\n",
    "\n",
    "        X_train_scaled = best_scaler.fit_transform(X_train)\n",
    "        X_test_scaled = best_scaler.transform(X_test)\n",
    "\n",
    "        X_train_reduced = best_encoder.transform(X_train_scaled)\n",
    "        X_test_reduced = best_encoder.transform(X_test_scaled)\n",
    "\n",
    "        clf = OneClassSVM(kernel=best_params['kernel'], gamma=best_params['gamma'], nu=best_params['nu'])\n",
    "        clf.fit(X_train_reduced)\n",
    "\n",
    "        pred_values = clf.predict(X_test_reduced)\n",
    "        true_values = [1 if y == 0 else -1 for y in y_test]\n",
    "\n",
    "        accuracy = accuracy_score(true_values, pred_values)\n",
    "        precision = precision_score(true_values, pred_values, zero_division=0.0)\n",
    "        recall = recall_score(true_values, pred_values)\n",
    "        f1 = f1_score(true_values, pred_values)\n",
    "\n",
    "        if accuracy > best_overall_accuracy:\n",
    "            best_overall_accuracy = accuracy\n",
    "            best_overall_params = best_params\n",
    "\n",
    "        logging.info(f\"outer cv number: {outer_cv_number}, accuracy: {accuracy}, precision: {precision}, recall: {recall}, f1: {f1} with params: {best_params}\")\n",
    "\n",
    "        accuracy_scores.append(accuracy)\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "    return {\n",
    "        'algorythm': 'OneClassSVM',\n",
    "        'best kernel': best_overall_params['kernel'],\n",
    "        'best gamma': best_overall_params['gamma'],\n",
    "        'best nu': best_overall_params['nu'],\n",
    "        'n_components': best_overall_params['components'],\n",
    "        'best scaler': best_overall_params['scaler'],\n",
    "        'score used for model selection': mod_selection_score.__name__,\n",
    "        'method used for model selection': 'nested cv',\n",
    "        'accuracy mean': np.mean(accuracy_scores) * 100,\n",
    "        'accuracy std': np.std(accuracy_scores) * 100,\n",
    "        'precision mean': np.mean(precision_scores) * 100,\n",
    "        'precision std': np.std(precision_scores) * 100,\n",
    "        'recall mean': np.mean(recall_scores) * 100,\n",
    "        'recall std': np.std(recall_scores) * 100,\n",
    "        'f1 mean': np.mean(f1_scores) * 100,\n",
    "        'f1 std': np.std(f1_scores) * 100,\n",
    "        'best overall accuracy': best_overall_accuracy * 100,\n",
    "        'class': positive_class\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "file_handler = logging.FileHandler('../logs/svm_pca_reduced.log')\n",
    "file_handler.setLevel(logging.INFO)\n",
    "file_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))\n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "logger.handlers = []\n",
    "logger.addHandler(file_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorythm</th>\n",
       "      <th>best kernel</th>\n",
       "      <th>best gamma</th>\n",
       "      <th>best nu</th>\n",
       "      <th>n_components</th>\n",
       "      <th>best scaler</th>\n",
       "      <th>score used for model selection</th>\n",
       "      <th>method used for model selection</th>\n",
       "      <th>accuracy mean</th>\n",
       "      <th>accuracy std</th>\n",
       "      <th>precision mean</th>\n",
       "      <th>precision std</th>\n",
       "      <th>recall mean</th>\n",
       "      <th>recall std</th>\n",
       "      <th>f1 mean</th>\n",
       "      <th>f1 std</th>\n",
       "      <th>best overall accuracy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OneClassSVM</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.336667</td>\n",
       "      <td>85</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>accuracy_score</td>\n",
       "      <td>nested cv</td>\n",
       "      <td>68.462824</td>\n",
       "      <td>6.589249</td>\n",
       "      <td>66.980638</td>\n",
       "      <td>6.181121</td>\n",
       "      <td>84.285714</td>\n",
       "      <td>11.780302</td>\n",
       "      <td>73.996800</td>\n",
       "      <td>5.897963</td>\n",
       "      <td>78.947368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OneClassSVM</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.336667</td>\n",
       "      <td>80</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>accuracy_score</td>\n",
       "      <td>nested cv</td>\n",
       "      <td>68.462824</td>\n",
       "      <td>6.589249</td>\n",
       "      <td>67.713239</td>\n",
       "      <td>5.783822</td>\n",
       "      <td>81.428571</td>\n",
       "      <td>14.568627</td>\n",
       "      <td>73.081468</td>\n",
       "      <td>6.922839</td>\n",
       "      <td>78.947368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OneClassSVM</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.336667</td>\n",
       "      <td>75</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>accuracy_score</td>\n",
       "      <td>nested cv</td>\n",
       "      <td>68.462824</td>\n",
       "      <td>6.589249</td>\n",
       "      <td>67.713239</td>\n",
       "      <td>5.783822</td>\n",
       "      <td>81.428571</td>\n",
       "      <td>14.568627</td>\n",
       "      <td>73.081468</td>\n",
       "      <td>6.922839</td>\n",
       "      <td>78.947368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OneClassSVM</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.336667</td>\n",
       "      <td>70</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>accuracy_score</td>\n",
       "      <td>nested cv</td>\n",
       "      <td>69.966583</td>\n",
       "      <td>5.020184</td>\n",
       "      <td>68.121402</td>\n",
       "      <td>5.081663</td>\n",
       "      <td>85.714286</td>\n",
       "      <td>11.780302</td>\n",
       "      <td>75.210427</td>\n",
       "      <td>4.861226</td>\n",
       "      <td>78.947368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OneClassSVM</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.316250</td>\n",
       "      <td>65</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>accuracy_score</td>\n",
       "      <td>nested cv</td>\n",
       "      <td>67.669173</td>\n",
       "      <td>6.421075</td>\n",
       "      <td>66.267007</td>\n",
       "      <td>6.507041</td>\n",
       "      <td>85.714286</td>\n",
       "      <td>11.780302</td>\n",
       "      <td>73.920413</td>\n",
       "      <td>5.074063</td>\n",
       "      <td>78.947368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>OneClassSVM</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.316250</td>\n",
       "      <td>60</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>accuracy_score</td>\n",
       "      <td>nested cv</td>\n",
       "      <td>69.298246</td>\n",
       "      <td>7.777055</td>\n",
       "      <td>68.354265</td>\n",
       "      <td>6.143796</td>\n",
       "      <td>81.428571</td>\n",
       "      <td>14.568627</td>\n",
       "      <td>73.567070</td>\n",
       "      <td>7.828303</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>OneClassSVM</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.132500</td>\n",
       "      <td>55</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>accuracy_score</td>\n",
       "      <td>nested cv</td>\n",
       "      <td>70.843776</td>\n",
       "      <td>7.345302</td>\n",
       "      <td>68.124019</td>\n",
       "      <td>6.364853</td>\n",
       "      <td>88.571429</td>\n",
       "      <td>12.453997</td>\n",
       "      <td>76.316770</td>\n",
       "      <td>6.528437</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>OneClassSVM</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.193750</td>\n",
       "      <td>50</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>accuracy_score</td>\n",
       "      <td>nested cv</td>\n",
       "      <td>74.644946</td>\n",
       "      <td>6.749102</td>\n",
       "      <td>72.715856</td>\n",
       "      <td>2.698445</td>\n",
       "      <td>84.285714</td>\n",
       "      <td>16.781914</td>\n",
       "      <td>77.287231</td>\n",
       "      <td>8.992612</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>OneClassSVM</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.255000</td>\n",
       "      <td>45</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>accuracy_score</td>\n",
       "      <td>nested cv</td>\n",
       "      <td>73.182957</td>\n",
       "      <td>7.291898</td>\n",
       "      <td>71.043956</td>\n",
       "      <td>5.534470</td>\n",
       "      <td>85.714286</td>\n",
       "      <td>13.997084</td>\n",
       "      <td>77.014493</td>\n",
       "      <td>7.389380</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>OneClassSVM</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.397917</td>\n",
       "      <td>40</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>accuracy_score</td>\n",
       "      <td>nested cv</td>\n",
       "      <td>71.512114</td>\n",
       "      <td>9.090373</td>\n",
       "      <td>70.626041</td>\n",
       "      <td>8.005612</td>\n",
       "      <td>82.857143</td>\n",
       "      <td>11.605769</td>\n",
       "      <td>75.702078</td>\n",
       "      <td>7.769268</td>\n",
       "      <td>84.210526</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>OneClassSVM</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.255000</td>\n",
       "      <td>35</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>accuracy_score</td>\n",
       "      <td>nested cv</td>\n",
       "      <td>69.214703</td>\n",
       "      <td>12.064690</td>\n",
       "      <td>67.060440</td>\n",
       "      <td>9.209404</td>\n",
       "      <td>87.142857</td>\n",
       "      <td>11.605769</td>\n",
       "      <td>75.407042</td>\n",
       "      <td>8.866066</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>OneClassSVM</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.275417</td>\n",
       "      <td>30</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>accuracy_score</td>\n",
       "      <td>nested cv</td>\n",
       "      <td>70.843776</td>\n",
       "      <td>7.922866</td>\n",
       "      <td>68.478545</td>\n",
       "      <td>7.081856</td>\n",
       "      <td>87.142857</td>\n",
       "      <td>11.605769</td>\n",
       "      <td>76.156148</td>\n",
       "      <td>6.730251</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>OneClassSVM</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.336667</td>\n",
       "      <td>85</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>f1_score</td>\n",
       "      <td>nested cv</td>\n",
       "      <td>68.462824</td>\n",
       "      <td>6.589249</td>\n",
       "      <td>66.980638</td>\n",
       "      <td>6.181121</td>\n",
       "      <td>84.285714</td>\n",
       "      <td>11.780302</td>\n",
       "      <td>73.996800</td>\n",
       "      <td>5.897963</td>\n",
       "      <td>78.947368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>OneClassSVM</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.336667</td>\n",
       "      <td>80</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>f1_score</td>\n",
       "      <td>nested cv</td>\n",
       "      <td>68.462824</td>\n",
       "      <td>6.589249</td>\n",
       "      <td>67.713239</td>\n",
       "      <td>5.783822</td>\n",
       "      <td>81.428571</td>\n",
       "      <td>14.568627</td>\n",
       "      <td>73.081468</td>\n",
       "      <td>6.922839</td>\n",
       "      <td>78.947368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>OneClassSVM</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.336667</td>\n",
       "      <td>75</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>f1_score</td>\n",
       "      <td>nested cv</td>\n",
       "      <td>66.959064</td>\n",
       "      <td>7.557221</td>\n",
       "      <td>65.332287</td>\n",
       "      <td>5.724277</td>\n",
       "      <td>82.857143</td>\n",
       "      <td>12.777531</td>\n",
       "      <td>72.648568</td>\n",
       "      <td>7.389456</td>\n",
       "      <td>78.947368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>OneClassSVM</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.336667</td>\n",
       "      <td>70</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>f1_score</td>\n",
       "      <td>nested cv</td>\n",
       "      <td>68.462824</td>\n",
       "      <td>6.589249</td>\n",
       "      <td>65.740450</td>\n",
       "      <td>5.204006</td>\n",
       "      <td>87.142857</td>\n",
       "      <td>8.806306</td>\n",
       "      <td>74.777527</td>\n",
       "      <td>5.670373</td>\n",
       "      <td>78.947368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>OneClassSVM</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.316250</td>\n",
       "      <td>65</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>f1_score</td>\n",
       "      <td>nested cv</td>\n",
       "      <td>67.669173</td>\n",
       "      <td>6.421075</td>\n",
       "      <td>66.267007</td>\n",
       "      <td>6.507041</td>\n",
       "      <td>85.714286</td>\n",
       "      <td>11.780302</td>\n",
       "      <td>73.920413</td>\n",
       "      <td>5.074063</td>\n",
       "      <td>78.947368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>OneClassSVM</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.316250</td>\n",
       "      <td>60</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>f1_score</td>\n",
       "      <td>nested cv</td>\n",
       "      <td>68.546366</td>\n",
       "      <td>7.568295</td>\n",
       "      <td>67.647828</td>\n",
       "      <td>6.285074</td>\n",
       "      <td>81.428571</td>\n",
       "      <td>14.568627</td>\n",
       "      <td>73.101231</td>\n",
       "      <td>7.629630</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>OneClassSVM</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.132500</td>\n",
       "      <td>55</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>f1_score</td>\n",
       "      <td>nested cv</td>\n",
       "      <td>69.340017</td>\n",
       "      <td>7.679749</td>\n",
       "      <td>66.805338</td>\n",
       "      <td>6.930077</td>\n",
       "      <td>88.571429</td>\n",
       "      <td>12.453997</td>\n",
       "      <td>75.422360</td>\n",
       "      <td>6.628926</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>OneClassSVM</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.193750</td>\n",
       "      <td>50</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>f1_score</td>\n",
       "      <td>nested cv</td>\n",
       "      <td>70.885547</td>\n",
       "      <td>8.145042</td>\n",
       "      <td>69.254317</td>\n",
       "      <td>6.246351</td>\n",
       "      <td>84.285714</td>\n",
       "      <td>16.781914</td>\n",
       "      <td>74.990224</td>\n",
       "      <td>8.972720</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>OneClassSVM</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.255000</td>\n",
       "      <td>45</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>f1_score</td>\n",
       "      <td>nested cv</td>\n",
       "      <td>73.182957</td>\n",
       "      <td>7.291898</td>\n",
       "      <td>71.043956</td>\n",
       "      <td>5.534470</td>\n",
       "      <td>85.714286</td>\n",
       "      <td>13.997084</td>\n",
       "      <td>77.014493</td>\n",
       "      <td>7.389380</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>OneClassSVM</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.397917</td>\n",
       "      <td>40</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>f1_score</td>\n",
       "      <td>nested cv</td>\n",
       "      <td>71.512114</td>\n",
       "      <td>9.090373</td>\n",
       "      <td>70.626041</td>\n",
       "      <td>8.005612</td>\n",
       "      <td>82.857143</td>\n",
       "      <td>11.605769</td>\n",
       "      <td>75.702078</td>\n",
       "      <td>7.769268</td>\n",
       "      <td>84.210526</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>OneClassSVM</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.255000</td>\n",
       "      <td>35</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>f1_score</td>\n",
       "      <td>nested cv</td>\n",
       "      <td>69.214703</td>\n",
       "      <td>12.064690</td>\n",
       "      <td>67.060440</td>\n",
       "      <td>9.209404</td>\n",
       "      <td>87.142857</td>\n",
       "      <td>11.605769</td>\n",
       "      <td>75.407042</td>\n",
       "      <td>8.866066</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>OneClassSVM</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.275417</td>\n",
       "      <td>30</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>f1_score</td>\n",
       "      <td>nested cv</td>\n",
       "      <td>70.843776</td>\n",
       "      <td>7.922866</td>\n",
       "      <td>68.478545</td>\n",
       "      <td>7.081856</td>\n",
       "      <td>87.142857</td>\n",
       "      <td>11.605769</td>\n",
       "      <td>76.156148</td>\n",
       "      <td>6.730251</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      algorythm best kernel  best gamma   best nu  n_components  \\\n",
       "0   OneClassSVM         rbf       0.001  0.336667            85   \n",
       "1   OneClassSVM         rbf       0.001  0.336667            80   \n",
       "2   OneClassSVM         rbf       0.001  0.336667            75   \n",
       "3   OneClassSVM         rbf       0.001  0.336667            70   \n",
       "4   OneClassSVM         rbf       0.001  0.316250            65   \n",
       "5   OneClassSVM         rbf       0.001  0.316250            60   \n",
       "6   OneClassSVM         rbf       0.001  0.132500            55   \n",
       "7   OneClassSVM         rbf       0.001  0.193750            50   \n",
       "8   OneClassSVM         rbf       0.001  0.255000            45   \n",
       "9   OneClassSVM         rbf       0.001  0.397917            40   \n",
       "10  OneClassSVM         rbf       0.001  0.255000            35   \n",
       "11  OneClassSVM         rbf       0.001  0.275417            30   \n",
       "12  OneClassSVM         rbf       0.001  0.336667            85   \n",
       "13  OneClassSVM         rbf       0.001  0.336667            80   \n",
       "14  OneClassSVM         rbf       0.001  0.336667            75   \n",
       "15  OneClassSVM         rbf       0.001  0.336667            70   \n",
       "16  OneClassSVM         rbf       0.001  0.316250            65   \n",
       "17  OneClassSVM         rbf       0.001  0.316250            60   \n",
       "18  OneClassSVM         rbf       0.001  0.132500            55   \n",
       "19  OneClassSVM         rbf       0.001  0.193750            50   \n",
       "20  OneClassSVM         rbf       0.001  0.255000            45   \n",
       "21  OneClassSVM         rbf       0.001  0.397917            40   \n",
       "22  OneClassSVM         rbf       0.001  0.255000            35   \n",
       "23  OneClassSVM         rbf       0.001  0.275417            30   \n",
       "\n",
       "         best scaler score used for model selection  \\\n",
       "0     MinMaxScaler()                 accuracy_score   \n",
       "1     MinMaxScaler()                 accuracy_score   \n",
       "2     MinMaxScaler()                 accuracy_score   \n",
       "3     MinMaxScaler()                 accuracy_score   \n",
       "4     MinMaxScaler()                 accuracy_score   \n",
       "5   StandardScaler()                 accuracy_score   \n",
       "6   StandardScaler()                 accuracy_score   \n",
       "7   StandardScaler()                 accuracy_score   \n",
       "8   StandardScaler()                 accuracy_score   \n",
       "9   StandardScaler()                 accuracy_score   \n",
       "10  StandardScaler()                 accuracy_score   \n",
       "11  StandardScaler()                 accuracy_score   \n",
       "12    MinMaxScaler()                       f1_score   \n",
       "13    MinMaxScaler()                       f1_score   \n",
       "14    MinMaxScaler()                       f1_score   \n",
       "15    MinMaxScaler()                       f1_score   \n",
       "16    MinMaxScaler()                       f1_score   \n",
       "17  StandardScaler()                       f1_score   \n",
       "18  StandardScaler()                       f1_score   \n",
       "19  StandardScaler()                       f1_score   \n",
       "20  StandardScaler()                       f1_score   \n",
       "21  StandardScaler()                       f1_score   \n",
       "22  StandardScaler()                       f1_score   \n",
       "23  StandardScaler()                       f1_score   \n",
       "\n",
       "   method used for model selection  accuracy mean  accuracy std  \\\n",
       "0                        nested cv      68.462824      6.589249   \n",
       "1                        nested cv      68.462824      6.589249   \n",
       "2                        nested cv      68.462824      6.589249   \n",
       "3                        nested cv      69.966583      5.020184   \n",
       "4                        nested cv      67.669173      6.421075   \n",
       "5                        nested cv      69.298246      7.777055   \n",
       "6                        nested cv      70.843776      7.345302   \n",
       "7                        nested cv      74.644946      6.749102   \n",
       "8                        nested cv      73.182957      7.291898   \n",
       "9                        nested cv      71.512114      9.090373   \n",
       "10                       nested cv      69.214703     12.064690   \n",
       "11                       nested cv      70.843776      7.922866   \n",
       "12                       nested cv      68.462824      6.589249   \n",
       "13                       nested cv      68.462824      6.589249   \n",
       "14                       nested cv      66.959064      7.557221   \n",
       "15                       nested cv      68.462824      6.589249   \n",
       "16                       nested cv      67.669173      6.421075   \n",
       "17                       nested cv      68.546366      7.568295   \n",
       "18                       nested cv      69.340017      7.679749   \n",
       "19                       nested cv      70.885547      8.145042   \n",
       "20                       nested cv      73.182957      7.291898   \n",
       "21                       nested cv      71.512114      9.090373   \n",
       "22                       nested cv      69.214703     12.064690   \n",
       "23                       nested cv      70.843776      7.922866   \n",
       "\n",
       "    precision mean  precision std  recall mean  recall std    f1 mean  \\\n",
       "0        66.980638       6.181121    84.285714   11.780302  73.996800   \n",
       "1        67.713239       5.783822    81.428571   14.568627  73.081468   \n",
       "2        67.713239       5.783822    81.428571   14.568627  73.081468   \n",
       "3        68.121402       5.081663    85.714286   11.780302  75.210427   \n",
       "4        66.267007       6.507041    85.714286   11.780302  73.920413   \n",
       "5        68.354265       6.143796    81.428571   14.568627  73.567070   \n",
       "6        68.124019       6.364853    88.571429   12.453997  76.316770   \n",
       "7        72.715856       2.698445    84.285714   16.781914  77.287231   \n",
       "8        71.043956       5.534470    85.714286   13.997084  77.014493   \n",
       "9        70.626041       8.005612    82.857143   11.605769  75.702078   \n",
       "10       67.060440       9.209404    87.142857   11.605769  75.407042   \n",
       "11       68.478545       7.081856    87.142857   11.605769  76.156148   \n",
       "12       66.980638       6.181121    84.285714   11.780302  73.996800   \n",
       "13       67.713239       5.783822    81.428571   14.568627  73.081468   \n",
       "14       65.332287       5.724277    82.857143   12.777531  72.648568   \n",
       "15       65.740450       5.204006    87.142857    8.806306  74.777527   \n",
       "16       66.267007       6.507041    85.714286   11.780302  73.920413   \n",
       "17       67.647828       6.285074    81.428571   14.568627  73.101231   \n",
       "18       66.805338       6.930077    88.571429   12.453997  75.422360   \n",
       "19       69.254317       6.246351    84.285714   16.781914  74.990224   \n",
       "20       71.043956       5.534470    85.714286   13.997084  77.014493   \n",
       "21       70.626041       8.005612    82.857143   11.605769  75.702078   \n",
       "22       67.060440       9.209404    87.142857   11.605769  75.407042   \n",
       "23       68.478545       7.081856    87.142857   11.605769  76.156148   \n",
       "\n",
       "      f1 std  best overall accuracy  class  \n",
       "0   5.897963              78.947368      0  \n",
       "1   6.922839              78.947368      0  \n",
       "2   6.922839              78.947368      0  \n",
       "3   4.861226              78.947368      0  \n",
       "4   5.074063              78.947368      0  \n",
       "5   7.828303              83.333333      0  \n",
       "6   6.528437              83.333333      0  \n",
       "7   8.992612              83.333333      0  \n",
       "8   7.389380              83.333333      0  \n",
       "9   7.769268              84.210526      0  \n",
       "10  8.866066              83.333333      0  \n",
       "11  6.730251              88.888889      0  \n",
       "12  5.897963              78.947368      0  \n",
       "13  6.922839              78.947368      0  \n",
       "14  7.389456              78.947368      0  \n",
       "15  5.670373              78.947368      0  \n",
       "16  5.074063              78.947368      0  \n",
       "17  7.629630              83.333333      0  \n",
       "18  6.628926              83.333333      0  \n",
       "19  8.972720              83.333333      0  \n",
       "20  7.389380              83.333333      0  \n",
       "21  7.769268              84.210526      0  \n",
       "22  8.866066              83.333333      0  \n",
       "23  6.730251              88.888889      0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = nested_cv_svm(X, random_seed, 0.16, decomposition=PCA, n_components=85, mod_selection_score=accuracy_score, positive_class=0)\n",
    "scores_df = pd.DataFrame(results, index=[0])\n",
    "\n",
    "for pca_comps in np.arange(80, 29, -5):\n",
    "    scores_df = add_record(scores_df, nested_cv_svm(X, random_seed, 0.16, decomposition=PCA, n_components=pca_comps, mod_selection_score=accuracy_score))\n",
    "\n",
    "for pca_comps in np.arange(85, 29, -5):\n",
    "    scores_df = add_record(scores_df, nested_cv_svm(X, random_seed, 0.16, decomposition=PCA, n_components=pca_comps, mod_selection_score=f1_score))\n",
    "\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "file_handler = logging.FileHandler('../logs/svm_mlp_reduced.log')\n",
    "file_handler.setLevel(logging.INFO)\n",
    "file_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))\n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "logger.handlers = []\n",
    "logger.addHandler(file_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderMLP:\n",
    "    def __init__(self, hidden_layer_size=60, max_iter=50, random_state=None, solver='sgd'):\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.max_iter = max_iter\n",
    "        self.random_state = random_state\n",
    "        self.solver = solver\n",
    "        self.model = MLPRegressor(hidden_layer_sizes=(self.hidden_layer_size,),\n",
    "                                  max_iter=self.max_iter,\n",
    "                                  random_state=self.random_state,\n",
    "                                  solver=self.solver)\n",
    "        \n",
    "        self.activation_map = {\n",
    "            'identity': lambda x: x,\n",
    "            'logistic': lambda x: 1 / (1 + np.exp(-x)),\n",
    "            'tanh': np.tanh,\n",
    "            'relu': lambda x: np.maximum(0, x)\n",
    "        }\n",
    "\n",
    "    def fit(self, X):\n",
    "        \"\"\"Addestra l'MLPRegressor con i dati forniti.\"\"\"\n",
    "        self.model.fit(X, X)\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"Ottiene le feature ridotte usando l'output del layer nascosto.\"\"\"\n",
    "        hidden_layer_output = np.dot(X, self.model.coefs_[0]) + self.model.intercepts_[0]\n",
    "        activation_func = self.activation_map[self.model.activation]\n",
    "        hidden_layer_output = activation_func(hidden_layer_output)\n",
    "        return hidden_layer_output\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        \"\"\"Addestra il modello e trasforma i dati in una sola chiamata.\"\"\"\n",
    "        self.fit(X)\n",
    "        return self.transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_cv_svm_mlp(X, random_seed, threshold, decomposition=EncoderMLP, n_outer_folds=7, n_inner_folds=5, n_components=65, mod_selection_score=accuracy_score, positive_class=0):\n",
    "    kernels = ['linear', 'rbf']\n",
    "    gammas = np.logspace(-3, 3, 7)\n",
    "    nus = np.linspace(0.01, 0.50, 25) \n",
    "    scalers = [StandardScaler(), MinMaxScaler(), RobustScaler()]\n",
    "    \n",
    "    best_params = {'kernel': '', 'gamma': 0, 'nu': 0, 'components': 0, 'scaler': ''}\n",
    "    accuracy_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "    best_overall_accuracy = 0\n",
    "    best_overall_params = {'kernel': '', 'gamma': 0, 'nu': 0, 'components': 0, 'scaler': ''}\n",
    "\n",
    "    y = X['Mezzo'].values\n",
    "    y = np.array([0. if x == positive_class else 1. for x in y], dtype=float)\n",
    "    \n",
    "    X = X.drop(columns='Mezzo')\n",
    "    X = filter_columns(X, threshold)\n",
    "\n",
    "    outer_cv = StratifiedKFold(n_splits=n_outer_folds, shuffle=True, random_state=random_seed)\n",
    "        \n",
    "    for outer_cv_number, (train_idx, test_idx) in enumerate(outer_cv.split(X, y)):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        inner_cv = StratifiedKFold(n_splits=n_inner_folds, shuffle=True, random_state=random_seed)\n",
    "\n",
    "        best_score = 0\n",
    "        best_scaler = None\n",
    "        best_encoder = None\n",
    "        for inner_cv_number, (trainval_idx, valid_idx) in enumerate(inner_cv.split(X_train, y_train)):\n",
    "            for kernel in kernels:\n",
    "                param_combinations = itertools.product([kernel], gammas, nus, scalers)\n",
    "                \n",
    "                if kernel == 'linear':\n",
    "                    param_combinations = itertools.product(['linear'], [0.001], nus, scalers)\n",
    "                elif kernel == 'rbf':\n",
    "                    param_combinations = itertools.product(['rbf'], gammas, nus, scalers)\n",
    "\n",
    "                for params in param_combinations:\n",
    "                    scaler = params[3]\n",
    "                    X_trainval, X_valid = X_train[trainval_idx], X_train[valid_idx]\n",
    "                    y_trainval, y_valid = y_train[trainval_idx], y_train[valid_idx]\n",
    "\n",
    "                    X_trainval_scaled = scaler.fit_transform(X_trainval)\n",
    "                    X_valid_scaled = scaler.transform(X_valid)\n",
    "\n",
    "                    encoder = decomposition(hidden_layer_size=n_components, max_iter=50, random_state=random_seed, solver='sgd')\n",
    "                    encoder.fit(X_train)\n",
    "                    \n",
    "                    X_trainval_reduced = encoder.transform(X_trainval_scaled)\n",
    "                    X_valid_reduced = encoder.transform(X_valid_scaled)\n",
    "                        \n",
    "                    idxs_neg = np.where(y_trainval == 1)[0]\n",
    "                \n",
    "                    X_trainval_reduced = np.delete(X_trainval_reduced, idxs_neg, axis=0)\n",
    "                    y_trainval = np.delete(y_trainval, idxs_neg)\n",
    "\n",
    "                    clf = OneClassSVM(kernel=params[0], gamma=params[1], nu=params[2])\n",
    "                        \n",
    "                    clf.fit(X_trainval_reduced)\n",
    "                        \n",
    "                    pred_values = clf.predict(X_valid_reduced)\n",
    "                    true_values = [1 if y == 0 else -1 for y in y_valid]\n",
    "                        \n",
    "                    score = mod_selection_score(true_values, pred_values)\n",
    "                    curr_params = {\n",
    "                            'kernel': params[0],\n",
    "                            'gamma': params[1],\n",
    "                            'nu': params[2],\n",
    "                            'components': n_components,\n",
    "                            'scaler': params[3]\n",
    "                    }\n",
    "\n",
    "                    logging.info(f\"inner cv number: {inner_cv_number}, {mod_selection_score.__name__}: {score}, with params: {curr_params}\")\n",
    "                            \n",
    "                    if score > best_score:\n",
    "                        best_score = score\n",
    "                        best_encoder = encoder\n",
    "                        best_scaler = scaler\n",
    "                        best_params = curr_params\n",
    "\n",
    "        idxs_neg = np.where(y_train == 1)[0]\n",
    "        X_train = np.delete(X_train, idxs_neg, axis=0)\n",
    "        y_train = np.delete(y_train, idxs_neg)\n",
    "\n",
    "        X_train_scaled = best_scaler.fit_transform(X_train)\n",
    "        X_test_scaled = best_scaler.transform(X_test)\n",
    "\n",
    "        X_train_reduced = best_encoder.transform(X_train_scaled)\n",
    "        X_test_reduced = best_encoder.transform(X_test_scaled)\n",
    "\n",
    "        clf = OneClassSVM(kernel=best_params['kernel'], gamma=best_params['gamma'], nu=best_params['nu'])\n",
    "        clf.fit(X_train_reduced)\n",
    "\n",
    "        pred_values = clf.predict(X_test_reduced)\n",
    "        true_values = [1 if y == 0 else -1 for y in y_test]\n",
    "\n",
    "        accuracy = accuracy_score(true_values, pred_values)\n",
    "        precision = precision_score(true_values, pred_values, zero_division=0.0)\n",
    "        recall = recall_score(true_values, pred_values)\n",
    "        f1 = f1_score(true_values, pred_values)\n",
    "\n",
    "        if accuracy > best_overall_accuracy:\n",
    "            best_overall_accuracy = accuracy\n",
    "            best_overall_params = best_params\n",
    "\n",
    "        logging.info(f\"outer cv number: {outer_cv_number}, accuracy: {accuracy}, precision: {precision}, recall: {recall}, f1: {f1} with params: {best_params}\")\n",
    "\n",
    "        accuracy_scores.append(accuracy)\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "    return {\n",
    "        'algorythm': 'OneClassSVM',\n",
    "        'best kernel': best_overall_params['kernel'],\n",
    "        'best gamma': best_overall_params['gamma'],\n",
    "        'best nu': best_overall_params['nu'],\n",
    "        'n_components': best_overall_params['components'],\n",
    "        'best scaler': best_overall_params['scaler'],\n",
    "        'score used for model selection': mod_selection_score.__name__,\n",
    "        'method used for model selection': 'nested cv',\n",
    "        'accuracy mean': np.mean(accuracy_scores) * 100,\n",
    "        'accuracy std': np.std(accuracy_scores) * 100,\n",
    "        'precision mean': np.mean(precision_scores) * 100,\n",
    "        'precision std': np.std(precision_scores) * 100,\n",
    "        'recall mean': np.mean(recall_scores) * 100,\n",
    "        'recall std': np.std(recall_scores) * 100,\n",
    "        'f1 mean': np.mean(f1_scores) * 100,\n",
    "        'f1 std': np.std(f1_scores) * 100,\n",
    "        'best overall accuracy': best_overall_accuracy * 100,\n",
    "        'class': positive_class\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorythm</th>\n",
       "      <th>best kernel</th>\n",
       "      <th>best gamma</th>\n",
       "      <th>best nu</th>\n",
       "      <th>n_components</th>\n",
       "      <th>best scaler</th>\n",
       "      <th>score used for model selection</th>\n",
       "      <th>method used for model selection</th>\n",
       "      <th>accuracy mean</th>\n",
       "      <th>accuracy std</th>\n",
       "      <th>precision mean</th>\n",
       "      <th>precision std</th>\n",
       "      <th>recall mean</th>\n",
       "      <th>recall std</th>\n",
       "      <th>f1 mean</th>\n",
       "      <th>f1 std</th>\n",
       "      <th>best overall accuracy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OneClassSVM</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>95</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>accuracy_score</td>\n",
       "      <td>nested cv</td>\n",
       "      <td>74.644946</td>\n",
       "      <td>6.749102</td>\n",
       "      <td>78.629704</td>\n",
       "      <td>10.017178</td>\n",
       "      <td>75.714286</td>\n",
       "      <td>15.907898</td>\n",
       "      <td>75.533059</td>\n",
       "      <td>8.016229</td>\n",
       "      <td>84.210526</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OneClassSVM</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.234583</td>\n",
       "      <td>90</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>accuracy_score</td>\n",
       "      <td>nested cv</td>\n",
       "      <td>66.207185</td>\n",
       "      <td>7.162007</td>\n",
       "      <td>69.301413</td>\n",
       "      <td>8.012644</td>\n",
       "      <td>68.571429</td>\n",
       "      <td>18.844151</td>\n",
       "      <td>67.407331</td>\n",
       "      <td>10.226087</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OneClassSVM</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.336667</td>\n",
       "      <td>85</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>accuracy_score</td>\n",
       "      <td>nested cv</td>\n",
       "      <td>74.561404</td>\n",
       "      <td>8.659824</td>\n",
       "      <td>81.289940</td>\n",
       "      <td>10.896003</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>13.093073</td>\n",
       "      <td>74.410641</td>\n",
       "      <td>9.321597</td>\n",
       "      <td>84.210526</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OneClassSVM</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.357083</td>\n",
       "      <td>80</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>accuracy_score</td>\n",
       "      <td>nested cv</td>\n",
       "      <td>63.116124</td>\n",
       "      <td>12.415645</td>\n",
       "      <td>66.244331</td>\n",
       "      <td>13.171746</td>\n",
       "      <td>64.285714</td>\n",
       "      <td>25.555063</td>\n",
       "      <td>62.842154</td>\n",
       "      <td>18.187221</td>\n",
       "      <td>84.210526</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OneClassSVM</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.316250</td>\n",
       "      <td>75</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>accuracy_score</td>\n",
       "      <td>nested cv</td>\n",
       "      <td>58.437761</td>\n",
       "      <td>8.581088</td>\n",
       "      <td>59.875223</td>\n",
       "      <td>7.160833</td>\n",
       "      <td>74.285714</td>\n",
       "      <td>12.936264</td>\n",
       "      <td>65.650276</td>\n",
       "      <td>6.688445</td>\n",
       "      <td>68.421053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>OneClassSVM</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.112083</td>\n",
       "      <td>70</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>accuracy_score</td>\n",
       "      <td>nested cv</td>\n",
       "      <td>65.455305</td>\n",
       "      <td>9.404157</td>\n",
       "      <td>67.152134</td>\n",
       "      <td>6.897065</td>\n",
       "      <td>68.571429</td>\n",
       "      <td>19.587585</td>\n",
       "      <td>66.684894</td>\n",
       "      <td>13.089089</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>OneClassSVM</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.397917</td>\n",
       "      <td>65</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>accuracy_score</td>\n",
       "      <td>nested cv</td>\n",
       "      <td>60.693400</td>\n",
       "      <td>10.683932</td>\n",
       "      <td>66.166175</td>\n",
       "      <td>9.718489</td>\n",
       "      <td>61.428571</td>\n",
       "      <td>20.303815</td>\n",
       "      <td>61.394431</td>\n",
       "      <td>11.918493</td>\n",
       "      <td>73.684211</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>OneClassSVM</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.275417</td>\n",
       "      <td>60</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>accuracy_score</td>\n",
       "      <td>nested cv</td>\n",
       "      <td>65.371763</td>\n",
       "      <td>14.482105</td>\n",
       "      <td>71.252398</td>\n",
       "      <td>16.800371</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>13.093073</td>\n",
       "      <td>68.825143</td>\n",
       "      <td>11.765970</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>OneClassSVM</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.132500</td>\n",
       "      <td>55</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>accuracy_score</td>\n",
       "      <td>nested cv</td>\n",
       "      <td>50.501253</td>\n",
       "      <td>10.626455</td>\n",
       "      <td>53.850733</td>\n",
       "      <td>7.315850</td>\n",
       "      <td>67.142857</td>\n",
       "      <td>13.850514</td>\n",
       "      <td>59.141129</td>\n",
       "      <td>8.122591</td>\n",
       "      <td>63.157895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>OneClassSVM</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.459167</td>\n",
       "      <td>50</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>accuracy_score</td>\n",
       "      <td>nested cv</td>\n",
       "      <td>68.546366</td>\n",
       "      <td>14.052357</td>\n",
       "      <td>74.585137</td>\n",
       "      <td>14.683562</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>22.677868</td>\n",
       "      <td>65.106815</td>\n",
       "      <td>19.465889</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>OneClassSVM</td>\n",
       "      <td>rbf</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.377500</td>\n",
       "      <td>45</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>accuracy_score</td>\n",
       "      <td>nested cv</td>\n",
       "      <td>59.983292</td>\n",
       "      <td>9.536991</td>\n",
       "      <td>67.981859</td>\n",
       "      <td>9.220594</td>\n",
       "      <td>48.571429</td>\n",
       "      <td>16.413036</td>\n",
       "      <td>55.230043</td>\n",
       "      <td>14.504684</td>\n",
       "      <td>73.684211</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>OneClassSVM</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.377500</td>\n",
       "      <td>40</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>accuracy_score</td>\n",
       "      <td>nested cv</td>\n",
       "      <td>61.821220</td>\n",
       "      <td>13.211954</td>\n",
       "      <td>64.884560</td>\n",
       "      <td>12.818642</td>\n",
       "      <td>57.142857</td>\n",
       "      <td>22.497165</td>\n",
       "      <td>59.685388</td>\n",
       "      <td>17.984644</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>OneClassSVM</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.275417</td>\n",
       "      <td>35</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>accuracy_score</td>\n",
       "      <td>nested cv</td>\n",
       "      <td>57.644110</td>\n",
       "      <td>10.745000</td>\n",
       "      <td>60.770975</td>\n",
       "      <td>11.109954</td>\n",
       "      <td>65.714286</td>\n",
       "      <td>13.997084</td>\n",
       "      <td>62.301587</td>\n",
       "      <td>10.179599</td>\n",
       "      <td>73.684211</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>OneClassSVM</td>\n",
       "      <td>rbf</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.418333</td>\n",
       "      <td>30</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>accuracy_score</td>\n",
       "      <td>nested cv</td>\n",
       "      <td>60.860485</td>\n",
       "      <td>9.732217</td>\n",
       "      <td>67.081014</td>\n",
       "      <td>15.449735</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>13.093073</td>\n",
       "      <td>61.985196</td>\n",
       "      <td>9.665991</td>\n",
       "      <td>72.222222</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      algorythm best kernel  best gamma   best nu  n_components  \\\n",
       "0   OneClassSVM         rbf       0.100  0.010000            95   \n",
       "1   OneClassSVM         rbf       0.100  0.234583            90   \n",
       "2   OneClassSVM         rbf       0.100  0.336667            85   \n",
       "3   OneClassSVM         rbf       0.100  0.357083            80   \n",
       "4   OneClassSVM         rbf       0.001  0.316250            75   \n",
       "5   OneClassSVM         rbf       0.001  0.112083            70   \n",
       "6   OneClassSVM         rbf       0.010  0.397917            65   \n",
       "7   OneClassSVM         rbf       0.100  0.275417            60   \n",
       "8   OneClassSVM         rbf       0.001  0.132500            55   \n",
       "9   OneClassSVM         rbf       0.100  0.459167            50   \n",
       "10  OneClassSVM         rbf       1.000  0.377500            45   \n",
       "11  OneClassSVM         rbf       0.100  0.377500            40   \n",
       "12  OneClassSVM         rbf       0.100  0.275417            35   \n",
       "13  OneClassSVM         rbf       0.010  0.418333            30   \n",
       "\n",
       "       best scaler score used for model selection  \\\n",
       "0   MinMaxScaler()                 accuracy_score   \n",
       "1   MinMaxScaler()                 accuracy_score   \n",
       "2   MinMaxScaler()                 accuracy_score   \n",
       "3   MinMaxScaler()                 accuracy_score   \n",
       "4   MinMaxScaler()                 accuracy_score   \n",
       "5   MinMaxScaler()                 accuracy_score   \n",
       "6   MinMaxScaler()                 accuracy_score   \n",
       "7   MinMaxScaler()                 accuracy_score   \n",
       "8   MinMaxScaler()                 accuracy_score   \n",
       "9   MinMaxScaler()                 accuracy_score   \n",
       "10  MinMaxScaler()                 accuracy_score   \n",
       "11  MinMaxScaler()                 accuracy_score   \n",
       "12  MinMaxScaler()                 accuracy_score   \n",
       "13  MinMaxScaler()                 accuracy_score   \n",
       "\n",
       "   method used for model selection  accuracy mean  accuracy std  \\\n",
       "0                        nested cv      74.644946      6.749102   \n",
       "1                        nested cv      66.207185      7.162007   \n",
       "2                        nested cv      74.561404      8.659824   \n",
       "3                        nested cv      63.116124     12.415645   \n",
       "4                        nested cv      58.437761      8.581088   \n",
       "5                        nested cv      65.455305      9.404157   \n",
       "6                        nested cv      60.693400     10.683932   \n",
       "7                        nested cv      65.371763     14.482105   \n",
       "8                        nested cv      50.501253     10.626455   \n",
       "9                        nested cv      68.546366     14.052357   \n",
       "10                       nested cv      59.983292      9.536991   \n",
       "11                       nested cv      61.821220     13.211954   \n",
       "12                       nested cv      57.644110     10.745000   \n",
       "13                       nested cv      60.860485      9.732217   \n",
       "\n",
       "    precision mean  precision std  recall mean  recall std    f1 mean  \\\n",
       "0        78.629704      10.017178    75.714286   15.907898  75.533059   \n",
       "1        69.301413       8.012644    68.571429   18.844151  67.407331   \n",
       "2        81.289940      10.896003    70.000000   13.093073  74.410641   \n",
       "3        66.244331      13.171746    64.285714   25.555063  62.842154   \n",
       "4        59.875223       7.160833    74.285714   12.936264  65.650276   \n",
       "5        67.152134       6.897065    68.571429   19.587585  66.684894   \n",
       "6        66.166175       9.718489    61.428571   20.303815  61.394431   \n",
       "7        71.252398      16.800371    70.000000   13.093073  68.825143   \n",
       "8        53.850733       7.315850    67.142857   13.850514  59.141129   \n",
       "9        74.585137      14.683562    60.000000   22.677868  65.106815   \n",
       "10       67.981859       9.220594    48.571429   16.413036  55.230043   \n",
       "11       64.884560      12.818642    57.142857   22.497165  59.685388   \n",
       "12       60.770975      11.109954    65.714286   13.997084  62.301587   \n",
       "13       67.081014      15.449735    60.000000   13.093073  61.985196   \n",
       "\n",
       "       f1 std  best overall accuracy  class  \n",
       "0    8.016229              84.210526      0  \n",
       "1   10.226087              77.777778      0  \n",
       "2    9.321597              84.210526      0  \n",
       "3   18.187221              84.210526      0  \n",
       "4    6.688445              68.421053      0  \n",
       "5   13.089089              77.777778      0  \n",
       "6   11.918493              73.684211      0  \n",
       "7   11.765970              88.888889      0  \n",
       "8    8.122591              63.157895      0  \n",
       "9   19.465889              88.888889      0  \n",
       "10  14.504684              73.684211      0  \n",
       "11  17.984644              83.333333      0  \n",
       "12  10.179599              73.684211      0  \n",
       "13   9.665991              72.222222      0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = nested_cv_svm_mlp(X, random_seed, 0.13, n_components=95, mod_selection_score=accuracy_score, positive_class=0)\n",
    "scores_df = pd.DataFrame(results, index=[0])\n",
    "\n",
    "for pca_comps in np.arange(90, 29, -5):\n",
    "    scores_df = add_record(scores_df, nested_cv_svm_mlp(X, random_seed, 0.13, n_components=pca_comps, mod_selection_score=accuracy_score))\n",
    "\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
