{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import itertools\n",
    "import pickle\n",
    "import logging\n",
    "from logging.handlers import RotatingFileHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130, 367)\n",
      "(130, 326)\n",
      "(130, 274)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/run-over-dataset.csv\")\n",
    "print(df.shape)\n",
    "\n",
    "columns_to_drop = ['VERBALE', 'DATA', 'Tot Testa', 'Tot Torace', 'Tot Addome', 'Tot Scheletro',\n",
    "                    'Totale', 'Tot Volta cranica', 'Tot Base cranica', \n",
    "                    'Tot Neuroc.', 'Tot Splancnoc.', 'Tot Testa',\n",
    "                    'Tot Tratto toracico', 'Tot Tratto lombare', 'Tot Rachide',\n",
    "                    ' Totale coste', 'Sterno in toto', 'Tot Bacino', 'I costa dx', 'II costa dx',\n",
    "                    'III costa dx', 'IV costa dx', 'V costa dx', 'VI costa dx', 'VII costa dx', \n",
    "                    'VIII costa dx', 'IX costa dx', 'X costa dx', 'XI costa dx', 'XII costa dx',\n",
    "                    'I costa sx', 'II costa sx', 'III costa sx', 'IV costa sx', 'V costa sx', \n",
    "                    'VI costa sx', 'VII costa sx', 'VIII costa sx', 'IX costa sx', \n",
    "                    'X costa sx', 'XI costa sx', 'XII costa sx']\n",
    "\n",
    "X = df.drop(columns=columns_to_drop)\n",
    "print(X.shape)\n",
    "\n",
    "X['ALTEZZA'] = [int(float(h.replace(',', '.'))*100) for h in X['ALTEZZA']]\n",
    "X['PESO'] = [int(float(str(h).replace(',', '.'))) for h in X['PESO']]\n",
    "X['BMI'] = [float(str(h).replace(',', '.')) for h in X['BMI']]\n",
    "\n",
    "num_unique_values = X.nunique()\n",
    "constant_columns = num_unique_values[num_unique_values == 1].index.tolist()\n",
    "\n",
    "X = X.drop(columns=constant_columns)\n",
    "X = X.T.drop_duplicates().T\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2456871, 1978223, 1880141, 2329972,  816489])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_seeds = np.random.randint(2343, 3485327, size=5)\n",
    "random_seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seeds = [2456871, 1978223, 1880141, 2329972,  816489]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_record(df, record):\n",
    "    new_record = pd.DataFrame(record, index=[0])\n",
    "    df = pd.concat([df, new_record], ignore_index=True)\n",
    "    return df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "file_handler = logging.FileHandler('if_nested_cv.log')\n",
    "file_handler.setLevel(logging.INFO)\n",
    "file_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))\n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "logger.handlers = []\n",
    "logger.addHandler(file_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_cv(X, random_seeds, n_outer_folds=5, n_inner_folds=3, pca_components=[], mod_selection_score=accuracy_score, positive_class=0):\n",
    "    n_estimatorss = np.arange(50, 201, 50)\n",
    "    contaminations = np.linspace(0.01, 0.5, 7)\n",
    "    max_featuress = np.linspace(0.1, 1.0, 5)\n",
    "    scalers = [StandardScaler(), MinMaxScaler(), RobustScaler()]\n",
    "    \n",
    "    best_params = {'n_estimators': 0, 'contamination': 0, 'max_features': 0, 'pca': 0, 'scaler': ''}\n",
    "    accuracy_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "    best_overall_accuracy = 0\n",
    "    best_overall_params = {'n_estimators': 0, 'contamination': 0, 'max_features': 0, 'pca': 0, 'scaler': ''}\n",
    "\n",
    "    y = X['Mezzo'].values\n",
    "    y = [0. if x==positive_class else 1. for x in y]\n",
    "    y = np.array(y, dtype=float)\n",
    "    \n",
    "    X = X.drop(columns='Mezzo').values\n",
    "\n",
    "    for seed in random_seeds:\n",
    "        outer_cv = StratifiedKFold(n_splits=n_outer_folds, shuffle=True, random_state=seed)\n",
    "        \n",
    "        for outer_cv_number, (train_idx, test_idx) in enumerate(outer_cv.split(X, y)):\n",
    "            X_train, X_test = X[train_idx], X[test_idx]\n",
    "            y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "            inner_cv = StratifiedKFold(n_splits=n_inner_folds, shuffle=True, random_state=seed)\n",
    "\n",
    "            best_score = 0\n",
    "            best_pipeline = Pipeline([('isolation_forest', IsolationForest())])\n",
    "            for inner_cv_number, (trainval_idx, valid_idx) in enumerate(inner_cv.split(X_train, y_train)):\n",
    "                X_trainval, X_valid = X_train[trainval_idx], X_train[valid_idx]\n",
    "                y_trainval, y_valid = y_train[trainval_idx], y_train[valid_idx]\n",
    "\n",
    "                idxs_neg = np.where(y_trainval == 1)[0]\n",
    "                X_valid = np.append(X_valid, X_trainval[idxs_neg], axis=0)\n",
    "                y_valid = np.append(y_valid, y_trainval[idxs_neg])\n",
    "\n",
    "                X_trainval = np.delete(X_trainval, idxs_neg, axis=0)\n",
    "                y_trainval = np.delete(y_trainval, idxs_neg)\n",
    "\n",
    "                \n",
    "                for params in itertools.product(n_estimatorss, contaminations, max_featuress, pca_components, scalers):\n",
    "                    pipeline = Pipeline([\n",
    "                        ('scaler', params[4]),\n",
    "                        ('pca', PCA(n_components=params[3])),\n",
    "                        ('isolation_forest', IsolationForest(n_estimators=params[0], contamination=params[1], max_features=params[2])) \n",
    "                    ])\n",
    "                    \n",
    "                    pipeline.fit(X_trainval)\n",
    "                    \n",
    "                    pred_values = pipeline.predict(X_valid)\n",
    "                    true_values = [1 if y == 0 else -1 for y in y_valid]\n",
    "                    \n",
    "                    score = mod_selection_score(true_values, pred_values)\n",
    "                    curr_params = {\n",
    "                            'n_estimators': params[0],\n",
    "                            'contamination': params[1],\n",
    "                            'max_features': params[2],\n",
    "                            'pca': params[3],\n",
    "                            'scaler': params[4]\n",
    "                        }\n",
    "                    logging.info(f\"inner cv number: {inner_cv_number}, {mod_selection_score.__name__}: {score}, with params: {curr_params}\")\n",
    "                        \n",
    "                    if score > best_score:\n",
    "                        best_score = score\n",
    "                        best_pipeline = pipeline\n",
    "                        best_params = curr_params\n",
    "\n",
    "            idxs_neg = np.where(y_train == 1)[0]\n",
    "            X_train = np.delete(X_train, idxs_neg, axis=0)\n",
    "\n",
    "            best_pipeline.fit(X_train)\n",
    "            pred_values = best_pipeline.predict(X_test)\n",
    "            true_values = [1 if y == 0 else -1 for y in y_test]\n",
    "\n",
    "            accuracy = accuracy_score(true_values, pred_values)\n",
    "            precision = precision_score(true_values, pred_values, zero_division=0.0)\n",
    "            recall = recall_score(true_values, pred_values)\n",
    "            f1 = f1_score(true_values, pred_values)\n",
    "\n",
    "            if accuracy > best_overall_accuracy:\n",
    "                best_overall_accuracy = accuracy_score(true_values, pred_values)\n",
    "                best_overall_params = best_params\n",
    "\n",
    "            logging.info(f\"outer cv number: {outer_cv_number}, accuracy: {score}, precision: {precision}, recall: {recall}, f1: {f1} with params: {curr_params}\")\n",
    "\n",
    "            accuracy_scores.append(accuracy)\n",
    "            precision_scores.append(precision)\n",
    "            recall_scores.append(recall)\n",
    "            f1_scores.append(f1)\n",
    "\n",
    "    return {'algorythm': 'IsolationForest',\n",
    "            'best n_estimators': best_overall_params['n_estimators'],\n",
    "            'best contamination': best_overall_params['contamination'],\n",
    "            'best max_features': best_overall_params['max_features'],\n",
    "            'best pca components': best_overall_params['pca'],\n",
    "            'best scaler': best_overall_params['scaler'],\n",
    "            'score used for model selection': mod_selection_score.__name__,\n",
    "            'method used for model selection': 'nested cv',\n",
    "            'accuracy mean': np.mean(accuracy_scores) * 100,\n",
    "            'accuracy std': np.std(accuracy_scores) * 100,\n",
    "            'precision mean': np.mean(precision_scores) * 100,\n",
    "            'precision  std': np.std(precision_scores) * 100,\n",
    "            'recall mean': np.mean(recall_scores) * 100,\n",
    "            'recall std': np.std(recall_scores) * 100,\n",
    "            'f1 mean': np.mean(f1_scores) * 100,\n",
    "            'f1 std': np.std(f1_scores) * 100,\n",
    "            'best overall accuracy': best_overall_accuracy * 100,\n",
    "            'class': positive_class}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorythm</th>\n",
       "      <th>best n_estimators</th>\n",
       "      <th>best contamination</th>\n",
       "      <th>best max_features</th>\n",
       "      <th>best pca components</th>\n",
       "      <th>best scaler</th>\n",
       "      <th>score used for model selection</th>\n",
       "      <th>method used for model selection</th>\n",
       "      <th>accuracy mean</th>\n",
       "      <th>accuracy std</th>\n",
       "      <th>precision mean</th>\n",
       "      <th>precision  std</th>\n",
       "      <th>recall mean</th>\n",
       "      <th>recall std</th>\n",
       "      <th>f1 mean</th>\n",
       "      <th>f1 std</th>\n",
       "      <th>best overall accuracy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IsolationForest</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>accuracy_score</td>\n",
       "      <td>nested cv</td>\n",
       "      <td>63.846154</td>\n",
       "      <td>7.133553</td>\n",
       "      <td>62.919677</td>\n",
       "      <td>5.075405</td>\n",
       "      <td>80.0</td>\n",
       "      <td>8.329931</td>\n",
       "      <td>70.365347</td>\n",
       "      <td>6.093081</td>\n",
       "      <td>76.923077</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         algorythm  best n_estimators  best contamination  best max_features  \\\n",
       "0  IsolationForest                 50                 0.5                1.0   \n",
       "\n",
       "   best pca components       best scaler score used for model selection  \\\n",
       "0                   35  StandardScaler()                 accuracy_score   \n",
       "\n",
       "  method used for model selection  accuracy mean  accuracy std  \\\n",
       "0                       nested cv      63.846154      7.133553   \n",
       "\n",
       "   precision mean  precision  std  recall mean  recall std    f1 mean  \\\n",
       "0       62.919677        5.075405         80.0    8.329931  70.365347   \n",
       "\n",
       "     f1 std  best overall accuracy  class  \n",
       "0  6.093081              76.923077      0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = nested_cv(X, random_seeds[0:1], pca_components=[20,28,35], mod_selection_score=accuracy_score, positive_class=0)\n",
    "scores_df = pd.DataFrame(results, index=[0])\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorythm</th>\n",
       "      <th>best n_estimators</th>\n",
       "      <th>best contamination</th>\n",
       "      <th>best max_features</th>\n",
       "      <th>best pca components</th>\n",
       "      <th>best scaler</th>\n",
       "      <th>score used for model selection</th>\n",
       "      <th>method used for model selection</th>\n",
       "      <th>accuracy mean</th>\n",
       "      <th>accuracy std</th>\n",
       "      <th>precision mean</th>\n",
       "      <th>precision  std</th>\n",
       "      <th>recall mean</th>\n",
       "      <th>recall std</th>\n",
       "      <th>f1 mean</th>\n",
       "      <th>f1 std</th>\n",
       "      <th>best overall accuracy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IsolationForest</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>accuracy_score</td>\n",
       "      <td>nested cv</td>\n",
       "      <td>63.846154</td>\n",
       "      <td>7.133553</td>\n",
       "      <td>62.919677</td>\n",
       "      <td>5.075405</td>\n",
       "      <td>80.0</td>\n",
       "      <td>8.329931</td>\n",
       "      <td>70.365347</td>\n",
       "      <td>6.093081</td>\n",
       "      <td>76.923077</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IsolationForest</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>f1_score</td>\n",
       "      <td>nested cv</td>\n",
       "      <td>66.923077</td>\n",
       "      <td>5.217177</td>\n",
       "      <td>64.777274</td>\n",
       "      <td>5.837249</td>\n",
       "      <td>90.0</td>\n",
       "      <td>10.690450</td>\n",
       "      <td>74.557812</td>\n",
       "      <td>2.470739</td>\n",
       "      <td>73.076923</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         algorythm  best n_estimators  best contamination  best max_features  \\\n",
       "0  IsolationForest                 50                 0.5                1.0   \n",
       "1  IsolationForest                 50                 0.5                1.0   \n",
       "\n",
       "   best pca components       best scaler score used for model selection  \\\n",
       "0                   35  StandardScaler()                 accuracy_score   \n",
       "1                   28    RobustScaler()                       f1_score   \n",
       "\n",
       "  method used for model selection  accuracy mean  accuracy std  \\\n",
       "0                       nested cv      63.846154      7.133553   \n",
       "1                       nested cv      66.923077      5.217177   \n",
       "\n",
       "   precision mean  precision  std  recall mean  recall std    f1 mean  \\\n",
       "0       62.919677        5.075405         80.0    8.329931  70.365347   \n",
       "1       64.777274        5.837249         90.0   10.690450  74.557812   \n",
       "\n",
       "     f1 std  best overall accuracy  class  \n",
       "0  6.093081              76.923077      0  \n",
       "1  2.470739              73.076923      0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = add_record(scores_df, nested_cv(X, random_seeds[0:1], pca_components=[20,28,35], mod_selection_score=f1_score, positive_class=0))\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'if_exp5_df.pickle'\n",
    "\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(scores_df, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorythm</th>\n",
       "      <th>best n_estimators</th>\n",
       "      <th>best contamination</th>\n",
       "      <th>best max_features</th>\n",
       "      <th>best pca components</th>\n",
       "      <th>best scaler</th>\n",
       "      <th>score used for model selection</th>\n",
       "      <th>method used for model selection</th>\n",
       "      <th>accuracy mean</th>\n",
       "      <th>accuracy std</th>\n",
       "      <th>precision mean</th>\n",
       "      <th>precision  std</th>\n",
       "      <th>recall mean</th>\n",
       "      <th>recall std</th>\n",
       "      <th>f1 mean</th>\n",
       "      <th>f1 std</th>\n",
       "      <th>best overall accuracy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IsolationForest</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>accuracy_score</td>\n",
       "      <td>nested cv</td>\n",
       "      <td>63.846154</td>\n",
       "      <td>7.133553</td>\n",
       "      <td>62.919677</td>\n",
       "      <td>5.075405</td>\n",
       "      <td>80.0</td>\n",
       "      <td>8.329931</td>\n",
       "      <td>70.365347</td>\n",
       "      <td>6.093081</td>\n",
       "      <td>76.923077</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IsolationForest</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>f1_score</td>\n",
       "      <td>nested cv</td>\n",
       "      <td>66.923077</td>\n",
       "      <td>5.217177</td>\n",
       "      <td>64.777274</td>\n",
       "      <td>5.837249</td>\n",
       "      <td>90.0</td>\n",
       "      <td>10.690450</td>\n",
       "      <td>74.557812</td>\n",
       "      <td>2.470739</td>\n",
       "      <td>73.076923</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         algorythm  best n_estimators  best contamination  best max_features  \\\n",
       "0  IsolationForest                 50                 0.5                1.0   \n",
       "1  IsolationForest                 50                 0.5                1.0   \n",
       "\n",
       "   best pca components       best scaler score used for model selection  \\\n",
       "0                   35  StandardScaler()                 accuracy_score   \n",
       "1                   28    RobustScaler()                       f1_score   \n",
       "\n",
       "  method used for model selection  accuracy mean  accuracy std  \\\n",
       "0                       nested cv      63.846154      7.133553   \n",
       "1                       nested cv      66.923077      5.217177   \n",
       "\n",
       "   precision mean  precision  std  recall mean  recall std    f1 mean  \\\n",
       "0       62.919677        5.075405         80.0    8.329931  70.365347   \n",
       "1       64.777274        5.837249         90.0   10.690450  74.557812   \n",
       "\n",
       "     f1 std  best overall accuracy  class  \n",
       "0  6.093081              76.923077      0  \n",
       "1  2.470739              73.076923      0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'if_exp5_df.pickle'\n",
    "\n",
    "with open(file_path, 'rb') as file:\n",
    "    scores_df = pickle.load(file)\n",
    "\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "file_handler = logging.FileHandler('if_nested_cv_100pca.log')\n",
    "file_handler.setLevel(logging.INFO)\n",
    "file_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))\n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "logger.handlers = []\n",
    "logger.addHandler(file_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_cv_extended(X, random_seeds, n_outer_folds=5, n_inner_folds=3, pca_components=[], mod_selection_score=accuracy_score, positive_class=0):\n",
    "    n_estimatorss = np.arange(50, 201, 50)\n",
    "    contaminations = np.linspace(0.01, 0.5, 7)\n",
    "    max_featuress = np.linspace(0.1, 1.0, 5)\n",
    "    scalers = [StandardScaler(), MinMaxScaler(), RobustScaler()]\n",
    "    \n",
    "    best_params = {'n_estimators': 0, 'contamination': 0, 'max_features': 0, 'pca': 0, 'scaler': ''}\n",
    "    accuracy_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "    best_overall_accuracy = 0\n",
    "    best_overall_params = {'n_estimators': 0, 'contamination': 0, 'max_features': 0, 'pca': 0, 'scaler': ''}\n",
    "\n",
    "    y = X['Mezzo'].values\n",
    "    y = np.array([0. if x == positive_class else 1. for x in y], dtype=float)\n",
    "    \n",
    "    X = X.drop(columns='Mezzo').values\n",
    "\n",
    "    for seed in random_seeds:\n",
    "        outer_cv = StratifiedKFold(n_splits=n_outer_folds, shuffle=True, random_state=seed)\n",
    "        \n",
    "        for outer_cv_number, (train_idx, test_idx) in enumerate(outer_cv.split(X, y)):\n",
    "            X_train, X_test = X[train_idx], X[test_idx]\n",
    "            y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "            inner_cv = StratifiedKFold(n_splits=n_inner_folds, shuffle=True, random_state=seed)\n",
    "\n",
    "            best_score = 0\n",
    "            best_pca = PCA()\n",
    "            best_scaler = StandardScaler()\n",
    "            for inner_cv_number, (trainval_idx, valid_idx) in enumerate(inner_cv.split(X_train, y_train)):\n",
    "                for params in itertools.product(n_estimatorss, contaminations, max_featuress, pca_components, scalers):\n",
    "                    scaler = params[4]\n",
    "                    X_trainval, X_valid = X_train[trainval_idx], X_train[valid_idx]\n",
    "                    y_trainval, y_valid = y_train[trainval_idx], y_train[valid_idx]\n",
    "\n",
    "                    X_trainval_scaled = scaler.fit_transform(X_trainval)\n",
    "                    X_valid_scaled = scaler.transform(X_valid)\n",
    "\n",
    "                    pca = PCA(n_components=params[3])\n",
    "                    X_trainval_reduced = pca.fit_transform(X_trainval_scaled)\n",
    "                    X_valid_reduced = pca.transform(X_valid_scaled)\n",
    "\n",
    "                    idxs_neg = np.where(y_trainval == 1)[0]\n",
    "                    X_trainval_reduced = np.delete(X_trainval_reduced, idxs_neg, axis=0)\n",
    "                    y_trainval = np.delete(y_trainval, idxs_neg)\n",
    "\n",
    "                    clf = IsolationForest(n_estimators=params[0], contamination=params[1], max_features=params[2])\n",
    "                    \n",
    "                    clf.fit(X_trainval_reduced)\n",
    "                    \n",
    "                    pred_values = clf.predict(X_valid_reduced)\n",
    "                    true_values = [1 if y == 0 else -1 for y in y_valid]\n",
    "                    \n",
    "                    score = mod_selection_score(true_values, pred_values)\n",
    "                    curr_params = {\n",
    "                            'n_estimators': params[0],\n",
    "                            'contamination': params[1],\n",
    "                            'max_features': params[2],\n",
    "                            'pca': params[3],\n",
    "                            'scaler': params[4]\n",
    "                    }\n",
    "\n",
    "                    logging.info(f\"inner cv number: {inner_cv_number}, {mod_selection_score.__name__}: {score}, with params: {curr_params}\")\n",
    "                        \n",
    "                    if score > best_score:\n",
    "                        best_score = score\n",
    "                        best_pca = pca\n",
    "                        best_scaler = scaler\n",
    "                        best_params = curr_params\n",
    "\n",
    "            idxs_neg = np.where(y_train == 1)[0]\n",
    "            X_train = np.delete(X_train, idxs_neg, axis=0)\n",
    "            y_train = np.delete(y_train, idxs_neg)\n",
    "\n",
    "            X_train_scaled = best_scaler.fit_transform(X_train)\n",
    "            X_test_scaled = best_scaler.transform(X_test)\n",
    "\n",
    "            X_train_reduced = best_pca.transform(X_train_scaled)\n",
    "            X_test_reduced = best_pca.transform(X_test_scaled)\n",
    "\n",
    "            clf = IsolationForest(n_estimators=best_params['n_estimators'], contamination=best_params['contamination'], max_features=best_params['max_features'])\n",
    "            clf.fit(X_train_reduced)\n",
    "\n",
    "            pred_values = clf.predict(X_test_reduced)\n",
    "            true_values = [1 if y == 0 else -1 for y in y_test]\n",
    "\n",
    "            accuracy = accuracy_score(true_values, pred_values)\n",
    "            precision = precision_score(true_values, pred_values, zero_division=0.0)\n",
    "            recall = recall_score(true_values, pred_values)\n",
    "            f1 = f1_score(true_values, pred_values)\n",
    "\n",
    "            if accuracy > best_overall_accuracy:\n",
    "                best_overall_accuracy = accuracy\n",
    "                best_overall_params = best_params\n",
    "\n",
    "            logging.info(f\"outer cv number: {outer_cv_number}, accuracy: {accuracy}, precision: {precision}, recall: {recall}, f1: {f1} with params: {best_params}\")\n",
    "\n",
    "            accuracy_scores.append(accuracy)\n",
    "            precision_scores.append(precision)\n",
    "            recall_scores.append(recall)\n",
    "            f1_scores.append(f1)\n",
    "\n",
    "    return {\n",
    "        'algorythm': 'IsolationForest',\n",
    "        'best n_estimators': best_overall_params['n_estimators'],\n",
    "        'best contamination': best_overall_params['contamination'],\n",
    "        'best max_features': best_overall_params['max_features'],\n",
    "        'best pca components': best_overall_params['pca'],\n",
    "        'best scaler': best_overall_params['scaler'],\n",
    "        'score used for model selection': mod_selection_score.__name__,\n",
    "        'method used for model selection': 'nested cv',\n",
    "        'accuracy mean': np.mean(accuracy_scores) * 100,\n",
    "        'accuracy std': np.std(accuracy_scores) * 100,\n",
    "        'precision mean': np.mean(precision_scores) * 100,\n",
    "        'precision  std': np.std(precision_scores) * 100,\n",
    "        'recall mean': np.mean(recall_scores) * 100,\n",
    "        'recall std': np.std(recall_scores) * 100,\n",
    "        'f1 mean': np.mean(f1_scores) * 100,\n",
    "        'f1 std': np.std(f1_scores) * 100,\n",
    "        'best overall accuracy': best_overall_accuracy * 100,\n",
    "        'class': positive_class\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorythm</th>\n",
       "      <th>best n_estimators</th>\n",
       "      <th>best contamination</th>\n",
       "      <th>best max_features</th>\n",
       "      <th>best pca components</th>\n",
       "      <th>best scaler</th>\n",
       "      <th>score used for model selection</th>\n",
       "      <th>method used for model selection</th>\n",
       "      <th>accuracy mean</th>\n",
       "      <th>accuracy std</th>\n",
       "      <th>precision mean</th>\n",
       "      <th>precision  std</th>\n",
       "      <th>recall mean</th>\n",
       "      <th>recall std</th>\n",
       "      <th>f1 mean</th>\n",
       "      <th>f1 std</th>\n",
       "      <th>best overall accuracy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IsolationForest</td>\n",
       "      <td>50</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>35</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>accuracy_score</td>\n",
       "      <td>nested cv</td>\n",
       "      <td>63.846154</td>\n",
       "      <td>7.133553</td>\n",
       "      <td>62.919677</td>\n",
       "      <td>5.075405</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.329931</td>\n",
       "      <td>70.365347</td>\n",
       "      <td>6.093081</td>\n",
       "      <td>76.923077</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IsolationForest</td>\n",
       "      <td>50</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>28</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>f1_score</td>\n",
       "      <td>nested cv</td>\n",
       "      <td>66.923077</td>\n",
       "      <td>5.217177</td>\n",
       "      <td>64.777274</td>\n",
       "      <td>5.837249</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>10.690450</td>\n",
       "      <td>74.557812</td>\n",
       "      <td>2.470739</td>\n",
       "      <td>73.076923</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IsolationForest</td>\n",
       "      <td>100</td>\n",
       "      <td>0.091667</td>\n",
       "      <td>0.325</td>\n",
       "      <td>100</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>accuracy_score</td>\n",
       "      <td>nested cv</td>\n",
       "      <td>63.076923</td>\n",
       "      <td>14.876215</td>\n",
       "      <td>67.399267</td>\n",
       "      <td>19.805760</td>\n",
       "      <td>65.641026</td>\n",
       "      <td>23.329106</td>\n",
       "      <td>64.197896</td>\n",
       "      <td>17.428678</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         algorythm  best n_estimators  best contamination  best max_features  \\\n",
       "0  IsolationForest                 50            0.500000              1.000   \n",
       "1  IsolationForest                 50            0.500000              1.000   \n",
       "2  IsolationForest                100            0.091667              0.325   \n",
       "\n",
       "   best pca components       best scaler score used for model selection  \\\n",
       "0                   35  StandardScaler()                 accuracy_score   \n",
       "1                   28    RobustScaler()                       f1_score   \n",
       "2                  100    MinMaxScaler()                 accuracy_score   \n",
       "\n",
       "  method used for model selection  accuracy mean  accuracy std  \\\n",
       "0                       nested cv      63.846154      7.133553   \n",
       "1                       nested cv      66.923077      5.217177   \n",
       "2                       nested cv      63.076923     14.876215   \n",
       "\n",
       "   precision mean  precision  std  recall mean  recall std    f1 mean  \\\n",
       "0       62.919677        5.075405    80.000000    8.329931  70.365347   \n",
       "1       64.777274        5.837249    90.000000   10.690450  74.557812   \n",
       "2       67.399267       19.805760    65.641026   23.329106  64.197896   \n",
       "\n",
       "      f1 std  best overall accuracy  class  \n",
       "0   6.093081              76.923077      0  \n",
       "1   2.470739              73.076923      0  \n",
       "2  17.428678              80.000000      0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = add_record(scores_df, nested_cv_extended(X, random_seeds[0:1], n_outer_folds=13, n_inner_folds=6, pca_components=[100, 88, 75], mod_selection_score=accuracy_score, positive_class=0))\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'if_exp5_df.pickle'\n",
    "\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(scores_df, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorythm</th>\n",
       "      <th>best n_estimators</th>\n",
       "      <th>best contamination</th>\n",
       "      <th>best max_features</th>\n",
       "      <th>best pca components</th>\n",
       "      <th>best scaler</th>\n",
       "      <th>score used for model selection</th>\n",
       "      <th>method used for model selection</th>\n",
       "      <th>accuracy mean</th>\n",
       "      <th>accuracy std</th>\n",
       "      <th>precision mean</th>\n",
       "      <th>precision  std</th>\n",
       "      <th>recall mean</th>\n",
       "      <th>recall std</th>\n",
       "      <th>f1 mean</th>\n",
       "      <th>f1 std</th>\n",
       "      <th>best overall accuracy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IsolationForest</td>\n",
       "      <td>50</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>35</td>\n",
       "      <td>StandardScaler()</td>\n",
       "      <td>accuracy_score</td>\n",
       "      <td>nested cv</td>\n",
       "      <td>63.846154</td>\n",
       "      <td>7.133553</td>\n",
       "      <td>62.919677</td>\n",
       "      <td>5.075405</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.329931</td>\n",
       "      <td>70.365347</td>\n",
       "      <td>6.093081</td>\n",
       "      <td>76.923077</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IsolationForest</td>\n",
       "      <td>50</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>28</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>f1_score</td>\n",
       "      <td>nested cv</td>\n",
       "      <td>66.923077</td>\n",
       "      <td>5.217177</td>\n",
       "      <td>64.777274</td>\n",
       "      <td>5.837249</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>10.690450</td>\n",
       "      <td>74.557812</td>\n",
       "      <td>2.470739</td>\n",
       "      <td>73.076923</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IsolationForest</td>\n",
       "      <td>100</td>\n",
       "      <td>0.091667</td>\n",
       "      <td>0.325</td>\n",
       "      <td>100</td>\n",
       "      <td>MinMaxScaler()</td>\n",
       "      <td>accuracy_score</td>\n",
       "      <td>nested cv</td>\n",
       "      <td>63.076923</td>\n",
       "      <td>14.876215</td>\n",
       "      <td>67.399267</td>\n",
       "      <td>19.805760</td>\n",
       "      <td>65.641026</td>\n",
       "      <td>23.329106</td>\n",
       "      <td>64.197896</td>\n",
       "      <td>17.428678</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IsolationForest</td>\n",
       "      <td>200</td>\n",
       "      <td>0.255000</td>\n",
       "      <td>0.325</td>\n",
       "      <td>88</td>\n",
       "      <td>RobustScaler()</td>\n",
       "      <td>f1_score</td>\n",
       "      <td>nested cv</td>\n",
       "      <td>62.307692</td>\n",
       "      <td>10.490909</td>\n",
       "      <td>65.256410</td>\n",
       "      <td>12.373511</td>\n",
       "      <td>75.897436</td>\n",
       "      <td>23.136675</td>\n",
       "      <td>67.101403</td>\n",
       "      <td>11.661966</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         algorythm  best n_estimators  best contamination  best max_features  \\\n",
       "0  IsolationForest                 50            0.500000              1.000   \n",
       "1  IsolationForest                 50            0.500000              1.000   \n",
       "2  IsolationForest                100            0.091667              0.325   \n",
       "3  IsolationForest                200            0.255000              0.325   \n",
       "\n",
       "   best pca components       best scaler score used for model selection  \\\n",
       "0                   35  StandardScaler()                 accuracy_score   \n",
       "1                   28    RobustScaler()                       f1_score   \n",
       "2                  100    MinMaxScaler()                 accuracy_score   \n",
       "3                   88    RobustScaler()                       f1_score   \n",
       "\n",
       "  method used for model selection  accuracy mean  accuracy std  \\\n",
       "0                       nested cv      63.846154      7.133553   \n",
       "1                       nested cv      66.923077      5.217177   \n",
       "2                       nested cv      63.076923     14.876215   \n",
       "3                       nested cv      62.307692     10.490909   \n",
       "\n",
       "   precision mean  precision  std  recall mean  recall std    f1 mean  \\\n",
       "0       62.919677        5.075405    80.000000    8.329931  70.365347   \n",
       "1       64.777274        5.837249    90.000000   10.690450  74.557812   \n",
       "2       67.399267       19.805760    65.641026   23.329106  64.197896   \n",
       "3       65.256410       12.373511    75.897436   23.136675  67.101403   \n",
       "\n",
       "      f1 std  best overall accuracy  class  \n",
       "0   6.093081              76.923077      0  \n",
       "1   2.470739              73.076923      0  \n",
       "2  17.428678              80.000000      0  \n",
       "3  11.661966              80.000000      0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = add_record(scores_df, nested_cv_extended(X, random_seeds[0:1], n_outer_folds=13, n_inner_folds=6, pca_components=[100, 88, 75], mod_selection_score=f1_score, positive_class=0))\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'if_exp5_df.pickle'\n",
    "\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(scores_df, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
