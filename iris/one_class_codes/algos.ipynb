{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing different algorythms on data set iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris(as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     class  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "..     ...  \n",
       "145      2  \n",
       "146      2  \n",
       "147      2  \n",
       "148      2  \n",
       "149      2  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "X, y = iris.data, iris.target\n",
    "X.insert(loc=4, column='class', value=y)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2, 0. ],\n",
       "       [4.9, 3. , 1.4, 0.2, 0. ],\n",
       "       [4.7, 3.2, 1.3, 0.2, 0. ],\n",
       "       [4.6, 3.1, 1.5, 0.2, 0. ],\n",
       "       [5. , 3.6, 1.4, 0.2, 0. ],\n",
       "       [5.4, 3.9, 1.7, 0.4, 0. ],\n",
       "       [4.6, 3.4, 1.4, 0.3, 0. ],\n",
       "       [5. , 3.4, 1.5, 0.2, 0. ],\n",
       "       [4.4, 2.9, 1.4, 0.2, 0. ],\n",
       "       [4.9, 3.1, 1.5, 0.1, 0. ],\n",
       "       [5.4, 3.7, 1.5, 0.2, 0. ],\n",
       "       [4.8, 3.4, 1.6, 0.2, 0. ],\n",
       "       [4.8, 3. , 1.4, 0.1, 0. ],\n",
       "       [4.3, 3. , 1.1, 0.1, 0. ],\n",
       "       [5.8, 4. , 1.2, 0.2, 0. ],\n",
       "       [5.7, 4.4, 1.5, 0.4, 0. ],\n",
       "       [5.4, 3.9, 1.3, 0.4, 0. ],\n",
       "       [5.1, 3.5, 1.4, 0.3, 0. ],\n",
       "       [5.7, 3.8, 1.7, 0.3, 0. ],\n",
       "       [5.1, 3.8, 1.5, 0.3, 0. ],\n",
       "       [5.4, 3.4, 1.7, 0.2, 0. ],\n",
       "       [5.1, 3.7, 1.5, 0.4, 0. ],\n",
       "       [4.6, 3.6, 1. , 0.2, 0. ],\n",
       "       [5.1, 3.3, 1.7, 0.5, 0. ],\n",
       "       [4.8, 3.4, 1.9, 0.2, 0. ],\n",
       "       [5. , 3. , 1.6, 0.2, 0. ],\n",
       "       [5. , 3.4, 1.6, 0.4, 0. ],\n",
       "       [5.2, 3.5, 1.5, 0.2, 0. ],\n",
       "       [5.2, 3.4, 1.4, 0.2, 0. ],\n",
       "       [4.7, 3.2, 1.6, 0.2, 0. ],\n",
       "       [4.8, 3.1, 1.6, 0.2, 0. ],\n",
       "       [5.4, 3.4, 1.5, 0.4, 0. ],\n",
       "       [5.2, 4.1, 1.5, 0.1, 0. ],\n",
       "       [5.5, 4.2, 1.4, 0.2, 0. ],\n",
       "       [4.9, 3.1, 1.5, 0.2, 0. ],\n",
       "       [5. , 3.2, 1.2, 0.2, 0. ],\n",
       "       [5.5, 3.5, 1.3, 0.2, 0. ],\n",
       "       [4.9, 3.6, 1.4, 0.1, 0. ],\n",
       "       [4.4, 3. , 1.3, 0.2, 0. ],\n",
       "       [5.1, 3.4, 1.5, 0.2, 0. ],\n",
       "       [5. , 3.5, 1.3, 0.3, 0. ],\n",
       "       [4.5, 2.3, 1.3, 0.3, 0. ],\n",
       "       [4.4, 3.2, 1.3, 0.2, 0. ],\n",
       "       [5. , 3.5, 1.6, 0.6, 0. ],\n",
       "       [5.1, 3.8, 1.9, 0.4, 0. ],\n",
       "       [4.8, 3. , 1.4, 0.3, 0. ],\n",
       "       [5.1, 3.8, 1.6, 0.2, 0. ],\n",
       "       [4.6, 3.2, 1.4, 0.2, 0. ],\n",
       "       [5.3, 3.7, 1.5, 0.2, 0. ],\n",
       "       [5. , 3.3, 1.4, 0.2, 0. ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setosa = X[X['class'] == 0].values\n",
    "setosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "versicolor, virginica = X[X['class'] == 1].values, X[X['class'] == 2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "clf = IsolationForest(n_estimators=110, contamination=0.01)\n",
    "X_train, X_test = train_test_split(setosa, test_size=0.2, random_state=10)\n",
    "\n",
    "clf.fit(X_train)\n",
    "\n",
    "preds_X = clf.predict(X_test)\n",
    "sum([1 if pred==1 else 0 for pred in preds_X]) / preds_X.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold \n",
    "\n",
    "def nested_cv(X, Y, Z):\n",
    "    n_estimators = [100, 150, 200]\n",
    "    max_samples = [0.5, 0.07, 1.0]\n",
    "    contaminations = [0.05, 0.1, 0.2]\n",
    "\n",
    "    b_params = ()\n",
    "    scores = []\n",
    "    error_rates = []\n",
    "\n",
    "    \n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "    for _, (train_idx, test_idx) in enumerate(cv.split(X)):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        inner_cv = KFold(n_splits=3, shuffle=True, random_state=0)\n",
    "\n",
    "        b_f1 = 0\n",
    "\n",
    "        for _, (train_idx1, valid_idx) in enumerate(inner_cv.split(X_train)):\n",
    "            X_train1, X_valid = X_train[train_idx1], X_train[valid_idx]\n",
    "\n",
    "            for n_est in n_estimators:\n",
    "                for max_s in max_samples:\n",
    "                    for contamination in contaminations:\n",
    "                            \n",
    "                        clf = IsolationForest(n_estimators=n_est, max_samples=max_s, contamination=contamination)\n",
    "                        clf.fit(X_train1)\n",
    "\n",
    "                        preds_X = clf.predict(X_valid)\n",
    "                        preds_Y = clf.predict(Y)\n",
    "                        preds_Z = clf.predict(Z)\n",
    "\n",
    "                        tp = sum([1 if pred==1 else 0 for pred in preds_X])\n",
    "                        tn = sum([1 if pred==-1 else 0 for pred in preds_Y]) + sum([1 if pred==-1 else 0 for pred in preds_Z])\n",
    "\n",
    "                        f1_score = (2 * tp) / (preds_X.size + preds_Y.size + preds_Z.size + tp - tn)\n",
    "\n",
    "                        if f1_score > b_f1:\n",
    "                            b_f1 = f1_score\n",
    "                            b_params = (n_est, max_s, contamination)\n",
    "\n",
    "\n",
    "        clf = IsolationForest(n_estimators=b_params[0], max_samples=b_params[1], contamination=b_params[2])\n",
    "        clf.fit(X_train)\n",
    "\n",
    "        preds_X = clf.predict(X_test)\n",
    "        preds_Y = clf.predict(Y)\n",
    "        preds_Z = clf.predict(Z)\n",
    "\n",
    "        score = sum([1 if pred==1 else 0 for pred in preds_X]) / preds_X.size \n",
    "        error_X = sum([1 if pred==-1 else 0 for pred in preds_X])\n",
    "        error_Y = sum([1 if pred==1 else 0 for pred in preds_Y])\n",
    "        error_Z = sum([1 if pred==1 else 0 for pred in preds_Z])\n",
    "\n",
    "        error_rate = (error_X + error_Y + error_Z) / (preds_X.size + preds_Y.size + preds_Z.size)\n",
    "\n",
    "        scores.append(score)\n",
    "        error_rates.append(error_rate)\n",
    "        \n",
    "    return np.mean(scores), np.mean(error_rates), np.std(scores), np.std(error_rates), b_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9400000000000001,\n",
       " 0.005454545454545454,\n",
       " 0.07999999999999999,\n",
       " 0.007272727272727272,\n",
       " (100, 0.5, 0.05))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nested_cv(setosa, virginica, versicolor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6799999999999999,\n",
       " 0.05818181818181819,\n",
       " 0.23151673805580456,\n",
       " 0.016861124537264918,\n",
       " (200, 1.0, 0.2))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nested_cv(virginica, setosa, versicolor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.76,\n",
       " 0.04727272727272727,\n",
       " 0.19595917942265423,\n",
       " 0.008907235428302466,\n",
       " (100, 1.0, 0.1))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nested_cv(versicolor, virginica, setosa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le prestazioni sono molto simili all'algoritmo OneClassSVM, che generalmente è migliore: ha score maggiori nel caso di setosa e virgina ma score peggiore per versicolor, errori minori per setosa e verginica e invece errore minore per versicolor. Il tempo di esecuzione è, invece, nettamente inferiore quello dell'algoritmo OneClassSVM.\n",
    "Da notare che non ho provato random_state differenti a causa del tempo di esecuzione troppo elevato, con l'algoritmo OneClassSVM, invece, avevo provato 20 random state differenti e poi avevo fatto la media."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "def nested_cv_lof(X, Y, Z):\n",
    "    n_neighbors = [5, 10, 15]\n",
    "    contaminations = [0.05, 0.1, 0.2]\n",
    "\n",
    "    b_params = ()\n",
    "    scores = []\n",
    "    error_rates = []\n",
    "\n",
    "    for i in range(21):\n",
    "        cv = KFold(n_splits=5, shuffle=True, random_state=i)\n",
    "\n",
    "        for _, (train_idx, test_idx) in enumerate(cv.split(X)):\n",
    "            X_train, X_test = X[train_idx], X[test_idx]\n",
    "\n",
    "            b_f1 = 0\n",
    "            inner_cv = KFold(n_splits=3, shuffle=True, random_state=i)\n",
    "\n",
    "            for _, (train_idx1, valid_idx) in enumerate(inner_cv.split(X_train)):\n",
    "                X_train1, X_valid = X_train[train_idx1], X_train[valid_idx]\n",
    "\n",
    "                for neighs in n_neighbors:\n",
    "                    for cont in contaminations:\n",
    "                        clf = LocalOutlierFactor(n_neighbors=neighs, contamination=cont, novelty=True)\n",
    "                        clf.fit(X_train1)\n",
    "\n",
    "                        preds_X = clf.predict(X_valid)\n",
    "                        preds_Y = clf.predict(Y)\n",
    "                        preds_Z = clf.predict(Z)\n",
    "\n",
    "                        tp = sum([1 if pred==1 else 0 for pred in preds_X])\n",
    "                        tn = sum([1 if pred==-1 else 0 for pred in preds_Y]) + sum([1 if pred==-1 else 0 for pred in preds_Z])\n",
    "\n",
    "                        f1_score = (2 * tp) / (preds_X.size + preds_Y.size + preds_Z.size + tp - tn)\n",
    "\n",
    "                        if f1_score > b_f1:\n",
    "                            b_f1 = f1_score\n",
    "                            b_params = (neighs, cont)\n",
    "\n",
    "            clf = LocalOutlierFactor(n_neighbors=b_params[0], contamination=b_params[1], novelty=True)\n",
    "            clf.fit(X_train)\n",
    "\n",
    "            preds_X = clf.predict(X_test)\n",
    "            preds_Y = clf.predict(Y)\n",
    "            preds_Z = clf.predict(Z)\n",
    "\n",
    "            score = sum([1 if pred==1 else 0 for pred in preds_X]) / preds_X.size \n",
    "            error_X = sum([1 if pred==-1 else 0 for pred in preds_X])\n",
    "            error_Y = sum([1 if pred==1 else 0 for pred in preds_Y])\n",
    "            error_Z = sum([1 if pred==1 else 0 for pred in preds_Z])\n",
    "\n",
    "            error_rate = (error_X + error_Y + error_Z) / (preds_X.size + preds_Y.size + preds_Z.size)\n",
    "\n",
    "            scores.append(score)\n",
    "            error_rates.append(error_rate)\n",
    "\n",
    "    return np.mean(scores), np.mean(error_rates), np.std(scores), np.std(error_rates), b_params \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9409523809523811,\n",
       " 0.005367965367965368,\n",
       " 0.08129339936332684,\n",
       " 0.007390309033029715,\n",
       " (5, 0.05))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nested_cv_lof(setosa, versicolor, virginica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9390476190476191,\n",
       " 0.005541125541125541,\n",
       " 0.09611029189746945,\n",
       " 0.008737299263406311,\n",
       " (5, 0.05))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nested_cv_lof(versicolor, setosa, virginica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9190476190476192,\n",
       " 0.007359307359307361,\n",
       " 0.1015079054817084,\n",
       " 0.009227991407428035,\n",
       " (5, 0.05))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nested_cv_lof(virginica, setosa, versicolor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sul data set ottengo prestazioni migliori utilizzando l'algoritmo LocalOutlierFactor. Le prestazioni sono simili per quanto riguarda la classe setosa, sono però decisamente migliori per quando riguarda le restanti classi, versicolor e virginica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
